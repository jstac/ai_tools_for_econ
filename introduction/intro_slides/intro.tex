\input{../../preamble}


\title{Computational Economics and the AI Revolution}



\author{John Stachurski}


\date{2025}


\begin{document}

\begin{frame}
  \titlepage
\end{frame}



\begin{frame}{Topics}

    \begin{enumerate}
        \item Introduction
        \vspace{0.5em}
        \item ANNs and deep learning
        \vspace{0.5em}
        \item ML and deep learning frameworks (programming)
        \vspace{0.5em}
        \item Stochastic approximation
        \vspace{0.5em}
        \item Dynamic programming
        \vspace{0.5em}
        \item Reinforcement learning
        \vspace{0.5em}
        \item Economic applications
    \end{enumerate}

\end{frame}



\begin{frame}{The AI revolution}


    \begin{itemize}
        \item generative AI  (LLMs, image / music / video)
        \vspace{0.5em}
        \item image processing / computer vision
        \vspace{0.5em}
        \item speech recognition
        \vspace{0.5em}
        \item translation
        \vspace{0.5em}
        \item scientific knowledge discovery
        \vspace{0.5em}
        \item forecasting and prediction 
        \vspace{0.5em}
        \item etc.
    \end{itemize}

    
\end{frame}


\begin{frame}
    
    \begin{figure}
       \centering
       \scalebox{0.24}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{alpha_fold.pdf}}
    \end{figure}

\end{frame}

\begin{frame}\frametitle{AlphaFold}

    \begin{itemize}
        \item AI system by DeepMind 
            \vspace{0.5em}
        \item Predicts 3D protein structures
            \vspace{0.5em}
        \item Open-sourced code and database 
            \vspace{0.5em}
        \item Accelerating drug discovery and design
            \vspace{0.5em}
        \item Enabling research on diseases like cancer and Alzheimer's
            \vspace{0.5em}
        \item Supporting enzyme engineering for sustainability
    \end{itemize}

            \vspace{0.5em}
            \vspace{0.5em}
            \vspace{0.5em}
    2024 Nobel Prize in Chemistry awarded to Demis Hassabis and John
    Jumper for development of AlphaFold

\end{frame}


\begin{frame}
    
    AlphaEvolve: A coding agent for scientific and algorithmic discovery

    Google Deepmind May 2025

    An evolutionary coding agent for tackling open scientific problems or
    optimizing critical pieces of computational infrastructure

    Using an evolutionary approach, continuously receiving feedback from one or
    more evaluators, AlphaEvolve iteratively improves the algorithm,
    potentially leading to new scientific and practical discoveries

    AlphaEvolve discovered novel, provably correct algorithms that surpass
    state-of-the-art solutions on a spectrum of problems in mathematics and
    computer science

\end{frame}

\begin{frame}
    \frametitle{LLMs}
    
    \begin{figure}
       \centering
       \scalebox{0.32}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{llms0.pdf}}
    \end{figure}

\end{frame}

\begin{frame}
    
    \begin{figure}
       \centering
       \scalebox{0.34}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{llms.pdf}}
    \end{figure}

\end{frame}


\begin{frame}
    
    \begin{figure}
       \centering
       \scalebox{0.3}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{llm3.pdf}}
    \end{figure}

\end{frame}


\begin{frame}{Gemini 2.5 Pro}
    
    \begin{figure}
       \centering
       \scalebox{0.5}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{gemini.pdf}}
    \end{figure}

\end{frame}

\begin{frame}
    \frametitle{Image Generators}
    
    \begin{figure}
       \centering
       \scalebox{0.3}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{image_gen.pdf}}
    \end{figure}

\end{frame}


\begin{frame}
    \frametitle{Weather forecasts}
    
    \begin{figure}
       \centering
       \scalebox{0.22}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{weather.pdf}}
    \end{figure}

\end{frame}


\begin{frame}

    
    ``ECMWF's weather forecasting model is considered the gold standard for
        medium-term weather forecasting\ldots 
        Google DeepMind claims to beat it 90\% of the time\ldots''

    \vspace{0.5em}
    \vspace{0.5em}

    ``Traditional forecasting models are big, complex computer algorithms based
    on atmospheric physics and take hours to run. AI models can create forecasts
    in just seconds.'' 
    \vspace{0.5em}
    \vspace{0.5em}

    $\quad \qquad$$\quad \qquad$ Source: MIT Technology Review  July 2024



\end{frame}



\begin{frame}
    \frametitle{Translation Engines}
    
    \begin{figure}
       \centering
       \scalebox{0.42}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{translation.pdf}}
    \end{figure}

\end{frame}


\begin{frame}{Killer drones, Skynet, etc.}

    \begin{figure}
       \centering
       \scalebox{0.46}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{terminator.png}}
    \end{figure}

\end{frame}

\begin{frame}{Investment}

    Private AI investment in 2024:

    \begin{itemize}
        \item U.S. = \$109 billion 
        \vspace{0.5em}
        \item China \$9.3 billion 
    \end{itemize}

        \vspace{0.5em}
    Estimate for US firms in 2025: \$350 billion

        \vspace{0.5em}
    Massive investments in 

    \begin{itemize}
        \item data centers
        \vspace{0.5em}
        \item server / GPU / TPU design and production
        \vspace{0.5em}
        \item software development
    \end{itemize}

\end{frame}


\begin{frame}
    
    What kinds of problems are they trying to solve?

\end{frame}




\begin{frame}{Statistical learning (induction)}
    
    We observe input-output pairs $(x, y)$, where
    %
    \begin{itemize}
        \item $x \in \RR^k$
        \item $y \in \RR$  (for example)
    \end{itemize}

    \Egs
    %
    \begin{itemize}
        \item $x = $ cross section of returns today, $y = $ return on oil futures tomorrow
        \vspace{0.5em}
        \item $x = $ weather sensor data today, $y = $ max temp tomorrow
    \end{itemize}
        \vspace{0.5em}
        \vspace{0.5em}

    Problem:

    \begin{itemize}
        \item observe $(x_i, y_i)_{i=1}^n$ and seek $f$ such that $y_{n+1}
            \approx f(x_{n+1})$
    \end{itemize}

\end{frame}


\begin{frame}{Deep Learning (DL)}

    Training:

    \begin{enumerate}
        \item Choose function class $\{f_\theta\}_{\theta \in \Theta}$ 
            \vspace{0.4em}
        \item Minimize loss 
            %
            \begin{equation*}
                \ell(\theta) := \sum_{i=1}^n (y_i - f_\theta(x_i))^2
                \quad \st \quad \theta \in \Theta
            \end{equation*}
    \end{enumerate}


    \pause
    \vspace{0.5em}
    In the case of DL, elements of $\{f_\theta\}_{\theta \in \Theta}$
    have a particular structure

    \begin{itemize}
        \item each $f_\theta$ is a neural net --- we discuss more soon
        \vspace{0.5em}
        \item typically, $\theta \mapsto f_\theta(x)$ is smooth for all $x$
        \vspace{0.5em}
        \item MSE is a popular loss function but others are also used
    \end{itemize}

\end{frame}


\begin{frame}
    

    Minimizing a smooth loss functions  -- what algorithm?
    
    \begin{figure}
       \begin{center}
        \scalebox{0.15}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{gdi.png}}
       \end{center}
    \end{figure}

    Source: \url{https://danielkhv.com/}

\end{frame}


\begin{frame}

    Deep learning: $\theta \in \RR^d$ where $d = ?$
    
    \begin{figure}
       \begin{center}
        \scalebox{0.14}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{loss2.jpg}}
       \end{center}
    \end{figure}

    Source: \url{https://losslandscape.com/gallery/}

\end{frame}




\begin{frame}
    \frametitle{How does it work?}
    
    How is it possible to minimize loss over such high dimensions??

        \vspace{0.5em}
        \vspace{0.5em}
        \vspace{0.5em}
        \vspace{0.5em}
        \pause

    Core elements
    %
    \begin{enumerate}
        \item parallelization over powerful hardware (GPUs or TPUs)
        \vspace{0.5em}
        \item automatic differentiation (for \underline{gradient} descent)
        \vspace{0.5em}
        \item Compilers / JIT-compilers for fast parallelized machine code
    \end{enumerate}

\end{frame}

\begin{frame}[fragile]
    \frametitle{Parallelization}

    \begin{figure}
       \begin{center}
        \scalebox{0.22}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{dgx.png}}
       \end{center}
    \end{figure}
    
\end{frame}

\begin{frame}[fragile]
    \frametitle{GPU architecture}
    \begin{figure}
        \centering
        \scalebox{0.09}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{gpu_arch.png}}
        \caption{NVIDIA H100 with 16896 CUDA cores and 128 
        streaming multiprocessors (SMs) ({\footnotesize
        \href{
           https://developer.nvidia.com/blog/nvidia-hopper-architecture-in-depth/
           }{NVIDIA Blog}})}
     \end{figure}
\end{frame}

\begin{frame}[fragile]
    \frametitle{Single-GPU parallelization}
  
    \vspace{0.5em}
    \begin{itemize}
      \item Vectorizes function across the many cores 
      (SMs).
      \item Automatically scales with more 
      multiprocessors on that one device.
    \end{itemize}
  
    \vspace{0.5em}
    \begin{minted}{python}
def function(data):
    # perform a calculation based on input data
    return output
vectorized_function = vmap(function)  
# Perform the same action on a batch of data sets
outputs = vectorized_function(data_sets)   
    \end{minted}
     {\footnotesize
     \href{https://github.com/stanford-cs336/spring2025-lectures/blob/main/nonexecutable/2025%20Lecture%205%20-%20GPUs.pdf
     }{More on GPUs}}
  \end{frame}

  \begin{frame}
    \begin{figure}
        \begin{center}
         \scalebox{0.75}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]
         {automatic-scalability.png}}
        \end{center}
     \end{figure}
     \footnotesize{
     \href{
        https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html?highlight=multiple%2520GPU#a-scalable-programming-model
        }{CUDA Documentation}
        }
  \end{frame}
  
  \begin{frame}[fragile]
    \frametitle{Multi-GPU parallelization}
  
    \vspace{0.5em}
    \begin{itemize}
      \item Splits your batch across several GPUs.
      \item Extended GPU Memory 
      (EGM) via NVLink lets GPUs in a node share memory.
    \end{itemize}
    \begin{figure}
        \begin{center}
         \scalebox{0.15}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]
         {egm-c2c-intro.png}}
        \end{center}
     \end{figure}
     \footnotesize{
        \href{https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html?highlight=multiple%2520GPU#unified-memory-introduction
    }{CUDA Documentation}}
    \vspace{0.5em}
    \begin{minted}{python}
parallel_function = pmap(function)  
outputs = parallel_function(list_of_tasks)  
    \end{minted}
  \end{frame}

\begin{frame}

    \textbf{\brown{Note: Full GPU-Python integration is on the way!}}
    
    \vspace{0.5em}
    At GTC 2025, NVIDIA announced native support and full integration of Python in its CUDA toolkit


    \vspace{0.5em}
    Over the last year, NVIDIA made CUDA Core -- a ``Pythonic
    reimagining of the CUDA runtime to be naturally and natively Python.''

    \vspace{0.5em}
    Coders can use natural Python interfaces and the scripting model of calling
    functions and libraries to create AI programs for execution on NVIDIA
    GPUs

    \vspace{0.5em}
    \vspace{0.5em}
    \vspace{0.5em}

    \footnotesize{
        \url{https://thenewstack.io/nvidia-finally-adds-native-python-support-to-cuda/}
    }

\end{frame}


\begin{frame}[fragile]
    \frametitle{Automatic differentiation}

    \vspace{0.5em}
    ``Exact numerical'' differentiation
    
    \begin{minted}{python}
from jax import grad

def f(θ, x):
    # add details here

def loss(θ, x, y):
  return jnp.sum((y - f(θ, x))**2)

loss_gradient = grad(loss)
d = loss_gradient(θ, x_data, y_data)
θ = θ - λ * d

    \end{minted}

\end{frame}


\begin{frame}[fragile]
    \frametitle{Just-in-time compilers}

    \vspace{0.5em}
    
    \begin{minted}{python}
@jax.jit
def f(x):
    return jnp.sin(x) - jnp.cos(x**2)
    \end{minted}

    \vspace{0.5em}
    \vspace{0.5em}
    Advantages over AOT compilers:

    \begin{itemize}
        \item cleaner code
    \vspace{0.5em}
        \item more portable
    \vspace{0.5em}
        \item lower compile times
    \vspace{0.5em}
        \item automatic parallelization (same code for CPUs / GPUs)
    \end{itemize}

\end{frame}



\begin{frame}
    \frametitle{Platforms}
    
    Platforms that support AI / deep learning:

    \vspace{0.5em}
    \begin{itemize}
        \item Tensorflow
        \vspace{0.5em}
        \item \brown{PyTorch} (Llama, ChatGPT)
        \vspace{0.5em}
        \item \brown{Google JAX} (Gemini, DeepMind)
        \vspace{0.5em}
        \item Keras (backends $=$ JAX, PyTorch)
        \vspace{0.5em}
        \item Mojo? (Modular (Python))
        \vspace{0.5em}
        \item MATLAB? 
    \end{itemize}

\end{frame}




\begin{frame}
    
    Popularity -- languages and libraries
    
    \begin{figure}
       \begin{center}
        \scalebox{0.62}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{trends.pdf}}
       \end{center}
    \end{figure}

\end{frame}


\begin{frame}
    
    Popularity -- DL / ML frameworks
    
    \begin{figure}
       \begin{center}
        \scalebox{0.62}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{trends_2.pdf}}
       \end{center}
    \end{figure}

\end{frame}



\begin{frame}{AI for coding}
    
    \begin{figure}
       \centering
       \scalebox{0.36}{\includegraphics[trim={0cm 0cm 0cm 0cm},clip]{code_ai.pdf}}
    \end{figure}

\end{frame}

\begin{frame}
    
    AI code generation is great\ldots but not perfect

\end{frame}


\begin{frame}

    Thoughts from pro developer \brown{\texttt{Lonely-Public2655}}

    \begin{itemize}
        \item AI doesn't see the big picture
        \vspace{0.5em}
        \item Can ace small tasks but struggles to connect them meaningfully
        \vspace{0.5em}
        \item \brown{You still need to be the architect}
        \vspace{0.5em}
        \item Context is fragile: AI forgets
        \vspace{0.5em}
        \item Once things get weird, AI starts guessing
        \vspace{0.5em}
        \item Sometimes AI gets really weird
    \end{itemize}

\end{frame}


\begin{frame}{AI coding affects optimal language choice}
    
    ``I'm definitely stronger with Python than MATLAB.''

    \vspace{0.5em}
    \vspace{0.5em}
    ``My capabilities with Python
    are more comprehensive. I have deeper familiarity with Python's extensive
    ecosystem of libraries, frameworks, and modern development practices.''


    \vspace{0.5em}
    \vspace{0.5em}
    ``I can
    more confidently help with advanced Python topics, debugging complex Python
    code, and implementing Python best practices.''

\end{frame}

\begin{frame}
    
    ``I'm definitely stronger with Python than Julia.''

    \vspace{0.5em}
    \vspace{0.5em}
    ``Python is one of my most proficient languages - I have deep familiarity with
    its syntax, libraries, frameworks, and best practices across many domains
    including data science, web development, machine learning, and
    general-purpose programming.''

    \vspace{0.5em}
    \vspace{0.5em}
    ``While I understand Julia's syntax and core concepts, my expertise with it
    isn't as comprehensive as with Python.''

\end{frame}

\begin{frame}
    \frametitle{AI tools for economic modeling}

    Let's say that you want to do computational economics without deep learning

    \vspace{0.5em}
    Can these new AI tools be applied?

    \pause

    \vspace{0.5em}
    \vspace{0.5em}
    \emp{Yes!}
    \emp{Yes!}
    \emp{Yes!}

    \begin{itemize}
        \item fast matrix algebra
        \vspace{0.5em}
        \item fast solutions to linear systems
        \vspace{0.5em}
        \item fast nonlinear system solvers
        \vspace{0.5em}
        \item fast optimization, etc.
    \end{itemize}


\end{frame}



\begin{frame}
    \frametitle{Case Study}

    The CBC uses the ``overborrowing'' model of Bianchi (2011)

    \begin{itemize}
        \item credit constraint loosens during booms
        \item bad shocks $\to$ sudden stops
    \end{itemize}

    \vspace{0.5em}
    CBC implementation in MATLAB 

    \begin{itemize}
        \item runs on \$10,000 mainframe with 356 CPUs and 1TB RAM
        \item runtime $=$ 12 hours
    \end{itemize}

    \pause
    \vspace{0.5em}
    Rewrite in Python + Google JAX

    \begin{itemize}
        \item runs on \$400 gaming GPU with 10GB RAM
        \item runtime $=$ 7 seconds
    \end{itemize}


\end{frame}

\begin{frame}{Summary}

    \begin{itemize}
        \item We are at the start of a massive AI revolution
        \vspace{0.2em}
        \item This revolution will have a huge impact on science
        \vspace{0.2em}
        \item What impact on economics?
    \end{itemize}

        \vspace{0.2em}
        \vspace{0.2em}
        \vspace{0.2em}
        \vspace{0.2em}
    \pause
    The aim of these lectures is \textbf{limited}

        \vspace{0.2em}
    \begin{itemize}
        \item Better understanding of core AI methods
        \vspace{0.2em}
        \item Better understanding of core tools (hardware / software)
        \vspace{0.2em}
        \item How can this knowledge be applied to economic modeling of today?
        \vspace{0.2em}
        \item Focus is on algorithms and numerical methods
    \end{itemize}

\end{frame}


\end{document}


